{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.layers import Activation\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.models import Model\n",
    "from keras.layers import Input\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.layers import UpSampling2D\n",
    "from keras.layers import Reshape\n",
    "import scipy.io as scio\n",
    "import numpy as np    \n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "from keras.layers import Concatenate\n",
    "from keras.layers import Lambda \n",
    "from keras.utils import to_categorical\n",
    "import tensorflow as tf\n",
    "from keras.layers import Add \n",
    "from keras import backend as K\n",
    "from keras import regularizers, optimizers\n",
    "import re\n",
    "from scipy.misc import imsave\n",
    "from scipy import ndimage, misc\n",
    "from numpy import unravel_index\n",
    "from operator import sub%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = np.load('home/kushalgbk/Desktop/acad/ai-asg2/complete_images.npy')\n",
    "y=np.load('home/kushalgbk/Desktop/acad/ai-asg2/gt.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_indices = np.random.choice(2000,1500,replace = False)\n",
    "x_train_images = []\n",
    "y_train_labels = [] \n",
    "for i in train_indices:\n",
    "    x_train_images.append(x[i])\n",
    "    y_train_labels.append(y[i])\n",
    "\n",
    "test_indices = [xy for xy in range(2000) if xy not in train_indices]\n",
    "print(test_indices)\n",
    "x_test_images = []\n",
    "y_test_labels = []\n",
    "\n",
    "for i in test_indices:\n",
    "    x_test_images.append(x[i])\n",
    "    y_test_labels.append(y[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_train = np.array(x_train_images)\n",
    "x_test = np.array(x_test_images)\n",
    "y_train = np.array(y_train_labels)\n",
    "y_test = np.array(y_test_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mean = np.mean(x_train,axis=(0,1,2,3))\n",
    "std = np.std(x_train,axis=(0,1,2,3))\n",
    "x_train = (x_train-mean)/(std+1e-7)\n",
    "x_test = (x_test-mean)/(std+1e-7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.save(\"x_train2.npy\",x_train)\n",
    "np.save(\"x_test2.npy\", x_test)\n",
    "np.save(\"y_train2.npy\",y_train)\n",
    "np.save(\"y_test2,npy\", y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_train = np.load('x_train2.npy')\n",
    "x_test = np.load('x_test2.npy')\n",
    "y_train = np.load('y_train2.npy')\n",
    "y_test = np.load('y_test2,npy.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rows = 256\n",
    "cols = 128data_shape = 216*64\n",
    "weight_decay = 0.0001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, None, None, 3 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, None, None, 6 1792        input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, None, None, 6 256         conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, None, None, 6 0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, None, None, 6 0           activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, None, None, 1 73856       max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, None, None, 1 512         conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, None, None, 1 0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, None, None, 1 0           activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, None, None, 1 147584      max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, None, None, 1 512         conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, None, None, 1 0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv_dil_1 (Conv2D)             (None, None, None, 1 147584      activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, None, None, 1 512         conv_dil_1[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, None, None, 1 0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv_dil_2 (Conv2D)             (None, None, None, 1 147584      activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, None, None, 1 512         conv_dil_2[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, None, None, 1 0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv_dil_3 (Conv2D)             (None, None, None, 1 147584      activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, None, None, 1 512         conv_dil_3[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, None, None, 1 0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "skip_conv_1 (Conv2D)            (None, None, None, 1 147584      max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, None, None, 1 0           activation_6[0][0]               \n",
      "                                                                 skip_conv_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_1 (UpSampling2D)  (None, None, None, 1 0           add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, None, None, 1 147584      up_sampling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, None, None, 1 512         conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, None, None, 1 0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "skip_conv_2 (Conv2D)            (None, None, None, 1 73856       max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, None, None, 1 0           activation_7[0][0]               \n",
      "                                                                 skip_conv_2[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_2 (UpSampling2D)  (None, None, None, 1 0           add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, None, None, 6 73792       up_sampling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, None, None, 6 256         conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, None, None, 6 0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, None, None, 1 65          activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, None, None, 1 0           conv2d_6[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 1,112,449\n",
      "Trainable params: 1,110,657\n",
      "Non-trainable params: 1,792\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "inputs = Input(shape=(None,None,3))\n",
    "\n",
    "L1 = Conv2D(64,kernel_size=(3,3),padding = \"same\",kernel_regularizer=regularizers.l2(weight_decay))(inputs)\n",
    "L2 = BatchNormalization()(L1)\n",
    "L2 = Activation('relu')(L2)\n",
    "L3 = MaxPooling2D(pool_size=(2,2))(L2)\n",
    "L4 = Conv2D(128,kernel_size=(3,3),padding = \"same\",kernel_regularizer=regularizers.l2(weight_decay))(L3)\n",
    "L5 = BatchNormalization()(L4)\n",
    "L5 = Activation('relu')(L5)\n",
    "L6 = MaxPooling2D(pool_size=(2,2))(L5)\n",
    "L7 = Conv2D(128,kernel_size=(3,3),padding = \"same\",kernel_regularizer=regularizers.l2(weight_decay))(L6)\n",
    "L8 = BatchNormalization()(L7)\n",
    "L9 = Activation('relu')(L8)\n",
    "L10 = Conv2D(128,(3,3),dilation_rate= (2,2), padding = \"same\", activation='relu', name = \"conv_dil_1\")(L9)\n",
    "L11 = BatchNormalization()(L10)\n",
    "L12 = Activation('relu')(L11)\n",
    "L13 = Conv2D(128,(3,3),dilation_rate= (4,4), padding = \"same\", activation='relu', name = \"conv_dil_2\")(L12)\n",
    "L14 = BatchNormalization()(L13)\n",
    "L15 = Activation('relu')(L14)\n",
    "L16 = Conv2D(128,(3,3),dilation_rate= (8,8), padding = \"same\", activation='relu', name = \"conv_dil_3\")(L15)\n",
    "L17 = BatchNormalization()(L16)\n",
    "L18 = Activation('relu')(L17)\n",
    "L19 = Conv2D(128,kernel_size=(3,3),padding = \"same\",kernel_regularizer=regularizers.l2(weight_decay),\n",
    "             name=\"skip_conv_1\")(L6)\n",
    "L20 = Add()([L18,L19])\n",
    "L21 = UpSampling2D( size = (2,2)) (L20)\n",
    "L21 = Conv2D(128,(3,3), padding = \"same\", kernel_regularizer=regularizers.l2(weight_decay))(L21)\n",
    "L22 = BatchNormalization()(L21)\n",
    "L23 = Activation('relu')(L22)\n",
    "L24 = Conv2D(128,kernel_size=(3,3),padding = \"same\",kernel_regularizer=regularizers.l2(weight_decay),\n",
    "             name=\"skip_conv_2\")(L3)\n",
    "L24 = Add()([L23,L24])\n",
    "L25 = UpSampling2D(size = (2,2))(L24)\n",
    "L25 = Conv2D(64, (3,3), padding = \"same\", kernel_regularizer=regularizers.l2(weight_decay))(L25)\n",
    "L26 = BatchNormalization()(L25)\n",
    "L27 = Activation('relu')(L26)\n",
    "L28 = Conv2D(1,kernel_size=(1,1),padding = \"same\",kernel_regularizer=regularizers.l2(weight_decay))(L27)#\n",
    "\n",
    "L30 = Activation('sigmoid')(L28)\n",
    "model = Model(inputs = inputs, outputs = L30)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_train = y_train.reshape(y_train.shape[0],256,256,1)\n",
    "y_test = y_test.reshape(y_test.shape[0],256,256,1)smooth = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def dice_coef(y_true, y_pred):\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred_f = K.flatten(y_pred)\n",
    "    intersection = K.sum(y_true_f * y_pred_f)\n",
    "    return (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n",
    "\n",
    "def dice_coef_loss(y_true, y_pred):\n",
    "    return -dice_coef(y_true, y_pred)\n",
    "\n",
    "def customized_loss(y_true,y_pred):\n",
    "    return (1*K.binary_crossentropy(y_true, y_pred))+(0.5*dice_coef_loss(y_true, y_pred))\n",
    "\n",
    "optimiser = optimizers.Adam(lr = 0.01)\n",
    "model.compile(optimizer=optimiser,loss=dice_coef_loss,metrics=['accuracy',dice_coef])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lr_reducer = ReduceLROnPlateau(factor=0.5, cooldown=0, patience=6, min_lr=0.5e-6)\n",
    "csv_logger = CSVLogger('segmentation_lr_e2_bs4.csv')\n",
    "model_chekpoint = ModelCheckpoint(\"segmentation_lr_e2_bs4.hdf5\",monitor = 'val_loss',verbose = 1,save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1500 samples, validate on 500 samples\n",
      "Epoch 1/20\n",
      "1500/1500 [==============================] - 11241s 7s/step - loss: -0.3401 - acc: 0.6109 - dice_coef: 0.3786 - val_loss: -0.3894 - val_acc: 0.6854 - val_dice_coef: 0.3523\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to -0.35187, saving model to segmentation_lr_e2_bs4.hdf5\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "`save_model` requires h5py.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-45-bd354e96f25d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mlr_reducer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcsv_logger\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmodel_chekpoint\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\python35\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[0;32m   1710\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1711\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1712\u001b[1;33m                               validation_steps=validation_steps)\n\u001b[0m\u001b[0;32m   1713\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1714\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[1;32mc:\\python35\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[1;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[0;32m   1253\u001b[0m                             \u001b[1;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mo\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval_outs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1254\u001b[0m                                 \u001b[0mepoch_logs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'val_'\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0ml\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mo\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1255\u001b[1;33m             \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_epoch_end\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1256\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mcallback_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstop_training\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1257\u001b[0m                 \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python35\\lib\\site-packages\\keras\\callbacks.py\u001b[0m in \u001b[0;36mon_epoch_end\u001b[1;34m(self, epoch, logs)\u001b[0m\n\u001b[0;32m     75\u001b[0m         \u001b[0mlogs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlogs\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     76\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mcallback\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 77\u001b[1;33m             \u001b[0mcallback\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_epoch_end\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     78\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     79\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mon_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python35\\lib\\site-packages\\keras\\callbacks.py\u001b[0m in \u001b[0;36mon_epoch_end\u001b[1;34m(self, epoch, logs)\u001b[0m\n\u001b[0;32m    445\u001b[0m                             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave_weights\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moverwrite\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    446\u001b[0m                         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 447\u001b[1;33m                             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moverwrite\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    448\u001b[0m                     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    449\u001b[0m                         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mverbose\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python35\\lib\\site-packages\\keras\\engine\\topology.py\u001b[0m in \u001b[0;36msave\u001b[1;34m(self, filepath, overwrite, include_optimizer)\u001b[0m\n\u001b[0;32m   2574\u001b[0m         \"\"\"\n\u001b[0;32m   2575\u001b[0m         \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0msave_model\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2576\u001b[1;33m         \u001b[0msave_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfilepath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moverwrite\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minclude_optimizer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2577\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2578\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0msave_weights\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfilepath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moverwrite\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python35\\lib\\site-packages\\keras\\models.py\u001b[0m in \u001b[0;36msave_model\u001b[1;34m(model, filepath, overwrite, include_optimizer)\u001b[0m\n\u001b[0;32m     58\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mh5py\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 60\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mImportError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'`save_model` requires h5py.'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     61\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget_json_type\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: `save_model` requires h5py."
     ]
    }
   ],
   "source": [
    "model.fit(x_train,y_train,batch_size=4,epochs=20,validation_data=(x_test, y_test),callbacks=[lr_reducer, csv_logger,model_chekpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x25d24b61c50>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x25d24b125f8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(gt, cmap = \"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gt = y_test[0].reshape((256,256))testing_image = x_test[0].reshape((1,256,256,3))\n",
    "prediction = model.predict(testing_image)\n",
    "prediction = prediction.reshape((256,256))\n",
    "sample = prediction > 0.5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x25d24ba4898>"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x25d24b75cf8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(sample, cmap = \"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
